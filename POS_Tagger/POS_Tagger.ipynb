{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pycrfsuite\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toatal number of sentences: 5233\n"
     ]
    }
   ],
   "source": [
    "#loading the data sentence wise\n",
    "def load_data(files):\n",
    "    data, sent = [], []\n",
    "    for file in files:\n",
    "        with open(file, 'r',encoding=\"utf8\") as rf:\n",
    "            for line in rf:\n",
    "                if line.strip() != '':\n",
    "                    sent.append(line.strip().split('\\t'))\n",
    "                else:\n",
    "                    if len(sent) > 0:\n",
    "                        data.append(sent)\n",
    "                        sent = []\n",
    "    return data\n",
    "\n",
    "sents = load_data(['data/FB_HI_EN_CR.txt', 'data/TWT_HI_EN_CR.txt', 'data/WA_HI_EN_CR.txt',\n",
    "                   'data/FB_BN_EN_CR.txt','data/TWT_BN_EN_CR.txt', 'data/WA_BN_EN_CR.txt',\n",
    "                  'data/FB_TE_EN_CR.txt', 'data/TWT_TE_EN_CR.txt', 'data/WA_TE_EN_CR.txt'])\n",
    "\n",
    "print('Toatal number of sentences:',len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sentences: 4186\n",
      "Validation sentences: 1047 \n",
      "\n",
      "train_sents_sample: \n",
      " [['Grad', 'en', 'G_N'], ['school', 'en', 'G_N'], ['dude', 'en', 'G_N'], ['!', 'univ', 'G_X']]\n",
      "\n",
      " valid_sents_sample: \n",
      " [['kya', 'hi', 'G_PRP'], ['hai', 'hi', 'G_V'], ['beeee', 'hi', 'G_PRP'], ['....????', 'univ', 'G_X']]\n"
     ]
    }
   ],
   "source": [
    "#shuffling data and splitting into train and test data\n",
    "random.seed(12)\n",
    "random.shuffle(sents)\n",
    "\n",
    "#80/20 split - train/valid\n",
    "train_sents = sents[:int(0.8*len(sents))]  \n",
    "valid_sents = sents[int(0.8*len(sents)):]\n",
    "print(\"Train sentences: %d\" % (len(train_sents)))\n",
    "print(\"Validation sentences: %d\" % (len(valid_sents)),'\\n')\n",
    "\n",
    "# Displaying a sample of train and validation sentences\n",
    "print('train_sents_sample:','\\n',train_sents[1])\n",
    "print('\\n','valid_sents_sample:','\\n',valid_sents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selected\n",
    "1. Current word\n",
    "2. Language of the current word\n",
    "3. Whether current word is alphanumeric or not ('True' / 'False')\n",
    "3. Character n-grams of the current word (n = 1 to 5 are selected)\n",
    "4. Begin and End of sentence markers (BOS and EOS)\n",
    "5. Context ( Previous word & Next Word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, k):\n",
    "    #current word\n",
    "    word = sent[k][0]\n",
    "    features = ['token=%s' % (word)]\n",
    "    \n",
    "    #Language of the current word\n",
    "    language = sent[k][1]\n",
    "    features.append(language)\n",
    "    \n",
    "    #Whether current word is alphanumeric or not ('True' / 'False')\n",
    "    features.append(str(word.isalnum()))\n",
    "    \n",
    "    # extracting n-grams, for n=1 to 5\n",
    "    for i in range(1,6):\n",
    "        # if the value of n is greater than the word length, we exit the loop\n",
    "        if i > len(word):\n",
    "            break\n",
    "        character_features = [word[j:j+i] for j in range(len(word)-i+1)]\n",
    "        features.extend([\n",
    "            # is count of individual n-grams important? is the order important?\n",
    "            \"char-%d-gram=%s\" % (i, ' '.join(list(set(character_features))))\n",
    "        ])\n",
    "    if k == 0:\n",
    "        # first word in the sentence\n",
    "        features.append('BOS')\n",
    "    else:\n",
    "        # previous word\n",
    "        features.extend([\n",
    "            \"-1:word=%s\" % (sent[k-1][0])\n",
    "        ])\n",
    "    if k == (len(sent)-1):\n",
    "        # last word in the sentence         \n",
    "        features.append('EOS')\n",
    "    else:\n",
    "        # next word\n",
    "        features.extend([\n",
    "            \"+1:word=%s\" % (sent[k+1][0])\n",
    "        ])\n",
    " \n",
    "    return features\n",
    "        \n",
    "def sent2features(sent):\n",
    "    # generating features for all the words/tokens in a sentence `sent`    \n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2pos(sent):\n",
    "    # obtaining parts of speech for all the words/tokens in a sentence `sent` \n",
    "    return [pos_tag for token, language_label, pos_tag in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, language_label, pos_tag in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['token=Grad', 'en', 'True', 'char-1-gram=G a r d', 'char-2-gram=ra Gr ad', 'char-3-gram=rad Gra', 'char-4-gram=Grad', 'BOS', '+1:word=school'], ['token=school', 'en', 'True', 'char-1-gram=s h c o l', 'char-2-gram=ol ch ho oo sc', 'char-3-gram=cho ool hoo sch', 'char-4-gram=scho hool choo', 'char-5-gram=schoo chool', '-1:word=Grad', '+1:word=dude'], ['token=dude', 'en', 'True', 'char-1-gram=d u e', 'char-2-gram=de ud du', 'char-3-gram=ude dud', 'char-4-gram=dude', '-1:word=school', '+1:word=!'], ['token=!', 'univ', 'False', 'char-1-gram=!', '-1:word=dude', 'EOS']]\n",
      "\n",
      " ['#', 'G_N', 'G_N', 'G_PRT', 'G_J', 'G_J', 'PSP', 'G_N', 'G_N', 'G_X', 'G_N', 'G_SYM', 'G_N', 'G_N', 'G_J', 'G_N', 'G_N', 'G_N', 'G_X', 'G_R', 'G_PRP', 'G_N', 'PSP', 'G_N', 'G_N', 'G_PRP', 'G_PRT', 'G_R', 'PSP', 'G_N', 'G_X', 'G_V', 'PSP', 'G_PRP', 'G_X', 'G_N', 'G_X', 'G_N', 'G_N', 'G_X', 'G_N']\n"
     ]
    }
   ],
   "source": [
    "# Obtaining traning and testing features from the given data\n",
    "X_train = [sent2features(sent) for sent in train_sents]\n",
    "y_train = [sent2pos(sent) for sent in train_sents]\n",
    "\n",
    "X_test = [sent2features(sent) for sent in valid_sents]\n",
    "y_test = [sent2pos(sent) for sent in valid_sents]\n",
    "\n",
    "# Displaying a sample of training data\n",
    "print(X_train[1])\n",
    "print('\\n',y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling Conditional Random Fields using pycrfsuite\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)  \n",
    "\n",
    "#appending (features,labels) to the model\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "#Setting model parameters\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 0.001,  # coefficient for L2 penalty\n",
    "    'max_iterations': 200, \n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('POS_model.crfsuite') #Training the model and saving it as POS_model.crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x284615a7cc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('POS_model.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@maheshaddict meeru malli prabhas fans tho kalisi snake dance cheseru akkada mee cinema range intha worst ani asalu expect cheyyale\n",
      "\n",
      "Predicted: @ G_PRP G_N G_N G_N PSP G_N G_N G_N G_N G_V G_PRP G_N G_N G_X G_J G_N G_N G_V G_N\n",
      "Correct:   @ G_X G_X G_N G_N PSP G_X G_N G_N G_X G_X G_PRP G_N G_N G_X G_J G_X G_X G_V G_X\n"
     ]
    }
   ],
   "source": [
    "example_sent = valid_sents[21]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2pos(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       0.74      0.47      0.57       220\n",
      "           $       0.76      0.54      0.63       190\n",
      "           @       0.77      0.95      0.85       501\n",
      "          CC       0.81      0.67      0.73       291\n",
      "          DT       0.86      0.82      0.84       490\n",
      "           E       0.94      0.77      0.85       156\n",
      "         G_J       0.79      0.49      0.61       880\n",
      "         G_N       0.70      0.89      0.78      5666\n",
      "       G_PRP       0.79      0.72      0.75      1154\n",
      "       G_PRT       0.66      0.47      0.55       452\n",
      "         G_R       0.79      0.61      0.69       513\n",
      "       G_SYM       0.69      0.44      0.53       149\n",
      "         G_V       0.80      0.65      0.72      2344\n",
      "         G_X       0.80      0.79      0.80      2944\n",
      "         PSP       0.80      0.67      0.73      1048\n",
      "           U       0.59      0.77      0.67       123\n",
      "        null       0.00      0.00      0.00        73\n",
      "           ~       1.00      0.32      0.48        22\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     17216\n",
      "   macro avg       0.74      0.61      0.65     17216\n",
      "weighted avg       0.76      0.75      0.75     17216\n",
      " samples avg       0.75      0.75      0.75     17216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "\n",
    "def analysis_report(y_true, y_pred):\n",
    "    # to convert the POS taggings into one-hot encoded format\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_coded = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_coded = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = list(lb.classes_)\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(y_true_coded,y_pred_coded,\n",
    "                                 labels= [class_indices[cls] for cls in tagset],\n",
    "                                 target_names = tagset)\n",
    "\n",
    "print(analysis_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7522653345724907\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Score \n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_true_coded = lb.fit_transform(list(chain.from_iterable(y_test)))\n",
    "y_pred_coded = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "\n",
    "import numpy as np\n",
    "y_true_labels = list(np.argmax(y_true_coded, axis=1))\n",
    "y_pred_labels = list(np.argmax(y_pred_coded, axis=1))\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_true_labels,y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
