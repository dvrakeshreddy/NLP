{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sentiment_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "320px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvrakeshreddy/NLP/blob/master/Sentiment_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lknphApudhR-"
      },
      "source": [
        "### Deep Sentiment Analysis Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NC9qqvWoJYZT"
      },
      "source": [
        "### Setup Environment\n",
        "- On Google Colab make sure you select Python 3/GPU runtime before running the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bnCJOwMIJhoE"
      },
      "source": [
        "#### Choose Python 3 + GPU/CPU\n",
        "\n",
        "<img src=\"https://i.stack.imgur.com/khwGc.png\" width=\"400\"></img>\n",
        "<img src=\"https://i.stack.imgur.com/5iL6w.png\" width=\"400\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VOC4ET1SdhSS",
        "outputId": "9ab8290e-3f72-4063-c6d6-c7b9f646ed43",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MuZFnhAHdhSj"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h8mTFaKcdhSl",
        "outputId": "bbac9b44-88f2-419f-fa28-88cac2e90a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "![ ! -d data ] && mkdir data/\n",
        "![ -f data/aclImdb_v1.tar.gz ] && echo \"Skip Download\"\n",
        "![ ! -f data/aclImdb_v1.tar.gz ] && wget -N https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -P data/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-26 13:28:26--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘data/aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  20.8MB/s    in 6.8s    \n",
            "\n",
            "2019-09-26 13:28:33 (11.8 MB/s) - ‘data/aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l8gzVXwxdhSr",
        "outputId": "11ab983c-5d27-4ed5-8c84-4ba013672b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "![ -d data/aclImdb/ ] && echo \"Data already extracted\"\n",
        "![ ! -d data/aclImdb/ ] && tar -xzf data/aclImdb_v1.tar.gz -C data/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 72.7 ms, sys: 18 ms, total: 90.7 ms\n",
            "Wall time: 11.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yJJMyQIHdhS6"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "md220_CQdhS_",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from tqdm import tqdm_notebook\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import seq2seq\n",
        "from tensorflow.contrib.rnn import DropoutWrapper\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ZSTVshldhTL",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WHeqBr6adhTX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2ffba075-e506-41d1-89dc-39241e02b580"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TNyzuzKpdhTl",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LEN = 100\n",
        "BATCH_SIZE = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a3alPCp0dhTw",
        "colab": {}
      },
      "source": [
        "class Lang:\n",
        "    def __init__(self, counter, vocab_size):\n",
        "        self.word2id = {}\n",
        "        self.id2word = {}\n",
        "        self.pad = \"<PAD>\"\n",
        "        self.sos = \"<SOS>\"\n",
        "        self.eos = \"<EOS>\"\n",
        "        self.unk = \"<UNK>\"\n",
        "        \n",
        "        self.ipad = 0\n",
        "        self.isos = 1\n",
        "        self.ieos = 2\n",
        "        self.iunk = 3\n",
        "        \n",
        "        self.word2id[self.pad] = 0\n",
        "        self.word2id[self.sos] = 1\n",
        "        self.word2id[self.eos] = 2\n",
        "        self.word2id[self.unk] = 3\n",
        "        \n",
        "        self.id2word[0] = self.pad\n",
        "        self.id2word[1] = self.sos\n",
        "        self.id2word[2] = self.eos\n",
        "        self.id2word[3] = self.unk\n",
        "        \n",
        "        curr_id = 4\n",
        "        for w, c in counter.most_common(vocab_size-curr_id):\n",
        "            self.word2id[w] = curr_id\n",
        "            self.id2word[curr_id] = w\n",
        "            curr_id += 1\n",
        "    \n",
        "    def encodeSentence(self, wseq, max_len=-1):\n",
        "        # wseq = nltk.tokenize.word_tokenize(s.lower().strip())\n",
        "        if max_len == -1:\n",
        "            return [self.word2id[w] if w in self.word2id else self.iunk for w in wseq]\n",
        "        else:\n",
        "            return ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
        "        \n",
        "    def encodeSentence2(self, wseq, max_len=-1):\n",
        "        # wseq = nltk.tokenize.word_tokenize(s.lower().strip()) \n",
        "        return min(max_len, len(wseq)+1), \\\n",
        "            ([self.word2id[w] if w in self.word2id else self.iunk for w in wseq] + \\\n",
        "                [self.ieos] + [self.ipad]*max_len)[:max_len]\n",
        "    \n",
        "    def decodeSentence(self, id_seq):\n",
        "        id_seq = np.array(id_seq + [self.ieos])\n",
        "        j = np.argmax(id_seq==self.ieos)\n",
        "        s = ' '.join([self.id2word[x] for x in id_seq[:j]])\n",
        "        s = s.replace(self.unk, \"UNK\")\n",
        "        return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YTsqaGfEKyku"
      },
      "source": [
        "### Let's read in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SJtY9mw6Kykv",
        "colab": {}
      },
      "source": [
        "data_folder = 'data/aclImdb/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mJOwy_iyKyky",
        "colab": {}
      },
      "source": [
        "rp = os.path.join(data_folder, 'train/pos')\n",
        "train_positive = [os.path.join(rp, f) for f in os.listdir(rp)]\n",
        "rp = os.path.join(data_folder, 'train/neg')\n",
        "train_negative = [os.path.join(rp, f) for f in os.listdir(rp)]\n",
        "\n",
        "rp = os.path.join(data_folder, 'test/pos')\n",
        "test_positive = [os.path.join(rp, f) for f in os.listdir(rp)]\n",
        "rp = os.path.join(data_folder, 'test/neg')\n",
        "test_negative = [os.path.join(rp, f) for f in os.listdir(rp)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TTY671XQKyk4",
        "colab": {}
      },
      "source": [
        "re_html_cleaner = re.compile(r\"<.*?>\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lIRoMacWdhU2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a6d50aa5-65e3-4c2d-dbd0-d03b14d47a9e"
      },
      "source": [
        "en_counter = Counter()\n",
        "train_data = []\n",
        "for _fname in tqdm_notebook(train_positive[:], desc=\"Crunching +ve samples: \"):\n",
        "    with open(_fname) as f:\n",
        "        text = f.read().strip()\n",
        "        text = re_html_cleaner.sub(\" \", text)\n",
        "        wseq = nltk.tokenize.word_tokenize(text.lower())\n",
        "        en_counter += Counter(wseq)\n",
        "        train_data.append((wseq, 1))\n",
        "        \n",
        "for _fname in tqdm_notebook(train_negative[:], desc=\"Crunching -ve samples: \"):\n",
        "    with open(_fname) as f:\n",
        "        text = f.read().strip()\n",
        "        text = re_html_cleaner.sub(\" \", text)\n",
        "        wseq = nltk.tokenize.word_tokenize(text.lower())\n",
        "        en_counter += Counter(wseq)\n",
        "        train_data.append((wseq, 0))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d990b5ef3f494d838e4e499ce19ede5c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Crunching +ve samples: ', max=12500, style=ProgressStyle(desc…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c28de34a4094e79b909e9f8b0b498d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Crunching -ve samples: ', max=12500, style=ProgressStyle(desc…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IHMLmx-odhVC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "98aaf117-1aa9-485b-dffd-711de39a5e58"
      },
      "source": [
        "test_data = []\n",
        "for _fname in tqdm_notebook(test_positive, desc=\"Crunching +ve samples: \"):\n",
        "    with open(_fname) as f:\n",
        "        text = f.read().strip()\n",
        "        text = re_html_cleaner.sub(\" \", text)\n",
        "        wseq = nltk.tokenize.word_tokenize(text.lower())\n",
        "        test_data.append((wseq, 1,_fname))\n",
        "        \n",
        "for _fname in tqdm_notebook(test_negative, desc=\"Crunching -ve samples: \"):\n",
        "    with open(_fname) as f:\n",
        "        text = f.read().strip()\n",
        "        text = re_html_cleaner.sub(\" \", text)\n",
        "        wseq = nltk.tokenize.word_tokenize(text.lower())\n",
        "        test_data.append((wseq, 0,_fname))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46578c5e9bdd419989d86b37fe95975f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Crunching +ve samples: ', max=12500, style=ProgressStyle(desc…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9389b822b53d4c548aca37a027aa755c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Crunching -ve samples: ', max=12500, style=ProgressStyle(desc…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H3zHTR09mPmR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90606126-925e-4b9d-d28a-806e88ad5be7"
      },
      "source": [
        "print(len(train_data),len(test_data))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "73BvAQl0dhVO",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "0b0d9b8f-cf38-4281-8dd1-6336cf88a938"
      },
      "source": [
        "# A few sample english words\n",
        "print(\"\\nMost common en words in dataset:\\n\", en_counter.most_common(10))\n",
        "\n",
        "print(\"\\nTotal (en)words gathered from dataset:\", len(en_counter))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Most common en words in dataset:\n",
            " [('the', 334679), (',', 275881), ('.', 271448), ('and', 163327), ('a', 162141), ('of', 145428), ('to', 135194), ('is', 110395), ('it', 95707), ('in', 93248)]\n",
            "\n",
            "Total (en)words gathered from dataset: 106415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "igqc71KjdhVZ",
        "colab": {}
      },
      "source": [
        "V = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "80kGgf1zdhVk",
        "colab": {}
      },
      "source": [
        "en_lang = Lang(en_counter, V)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FsvkqwUsdhVv",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f27e81ca-81de-48ac-ac1b-e369997926c8"
      },
      "source": [
        "wseq = nltk.tokenize.word_tokenize(\"Where are you going?\".lower())\n",
        "print(\"Test en encoding:\", en_lang.encodeSentence(wseq))\n",
        "print(\"Test en decoding:\", en_lang.decodeSentence(en_lang.encodeSentence(wseq, 10)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test en encoding: [131, 33, 27, 182, 58]\n",
            "Test en decoding: where are you going ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1VcSAkTgdhWO"
      },
      "source": [
        "### The RNN based Sentence Classifier architecture\n",
        "- We will implement a RNN based classifier architecture for sentiment analysis in Tensorflow r1.13.1 / r1.14\n",
        "- Debugging Tip: Always keep track of tensor dimensions!\n",
        "- **Tensorflow Computation Graph** - We will build a tf computation graph first. This is the representation used by tf for any neural network architecture. Once the computation graph is built, you can feed data to it for training or inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L2Or6h63dhWZ"
      },
      "source": [
        "#### Word Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BK6tim88dhWe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a7c62a70-798a-4265-e83f-8596b659f740"
      },
      "source": [
        "en_word_emb_matrix = tf.get_variable(\"en_word_emb_matrix\", (V, 300), dtype=tf.float32)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2MZJ3omDdhWu"
      },
      "source": [
        "#### Placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nhXAQtRrdhWx",
        "colab": {}
      },
      "source": [
        "keep_prob = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zWzq5y4fdhW8",
        "colab": {}
      },
      "source": [
        "input_ids = tf.placeholder(tf.int32, (None, MAX_SEQ_LEN))\n",
        "input_lens = tf.placeholder(tf.int32, (None, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ckx5kzf8dhXN",
        "colab": {}
      },
      "source": [
        "y_placeholder = tf.placeholder(tf.int32, (None,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MueO9VCIdhXY"
      },
      "source": [
        "#### Tensorflow Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qVT9MmD7dhXb",
        "colab": {}
      },
      "source": [
        "input_emb = tf.nn.embedding_lookup(en_word_emb_matrix, input_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DdzPmsUSdhXm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d04bc33d-8156-493f-ba18-c63323234066"
      },
      "source": [
        "input_emb.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(100), Dimension(300)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kSPg2ieMdhXw"
      },
      "source": [
        "#### Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GjYe11QndhXy"
      },
      "source": [
        "##### RNN Units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fGb3RcDQdhX2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "d016350c-25c9-4b14-8c07-a4704c69f6f1"
      },
      "source": [
        "# Create a single GRU cell\n",
        "encoder_cell = tf.nn.rnn_cell.GRUCell(128)\n",
        "# Add dropout : Dropout is applied to the hidden state output at every time step\n",
        "encoder_cell = DropoutWrapper(encoder_cell, output_keep_prob=keep_prob)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-d9e8bf943dab>:1: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wM6dOAg5dhX_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "bd86949a-13a4-4d54-fee3-4fb517baf18c"
      },
      "source": [
        "# Unrolling of time-sequence\n",
        "# Apply the encoder cell on input sequence and unroll computation upto\n",
        "# max sequence length\n",
        "enc_outputs, enc_state = tf.nn.dynamic_rnn(\n",
        "    encoder_cell, input_emb, sequence_length=input_lens, initial_state=encoder_cell.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-20566d338e2e>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:574: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hxQzqxtldhYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94436af9-1fb5-4f6e-dde1-72313182a29f"
      },
      "source": [
        "enc_outputs.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(50), Dimension(100), Dimension(128)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OcKWfCKtdhYb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "088bf5c2-4aa1-4844-9bda-a3b02455f0fa"
      },
      "source": [
        "enc_state.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(50), Dimension(128)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HppWE0twdhYq"
      },
      "source": [
        "### Classifier Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7hG4EdgUdhYs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7babfcff-5f5f-40f4-86aa-b55a808dd970"
      },
      "source": [
        "# A simple fully connected linear layer\n",
        "# W^T*X + b\n",
        "\n",
        "layer1 = tf.layers.dense(inputs=enc_state, units=64, activation=tf.nn.relu)\n",
        "layer2 = tf.layers.dense(inputs=layer1, units=16, activation=tf.nn.relu)\n",
        "dense_layer = tf.layers.dense(inputs=layer2, units=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-30-c7b38074475c>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HnPjquffdhY2"
      },
      "source": [
        "#### Approaches:\n",
        "As input to the final linear layers use mean of the hidden states?\n",
        "\n",
        "or\n",
        "\n",
        "As input to the final linear layers use the last hidden state?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "voVZLSyNdhY5"
      },
      "source": [
        "##### Approch 1: Take mean of enc_outputs across dimension 1\n",
        "- **IMPORTANT:** Need to **mask** the positions in input sentence that doesn't contain any inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WnrW-59FdhY7",
        "colab": {}
      },
      "source": [
        "# masks = tf.sequence_mask(input_lens, MAX_SEQ_LEN, dtype=tf.float32, name='masks')\n",
        "# class_prob = tf.nn.sigmoid(\n",
        "#                 dense_layer(\n",
        "#                     tf.reduce_mean(\n",
        "#                         enc_outputs*masks[:, :, None], 1)\n",
        "#                 )\n",
        "# ) \n",
        "\n",
        "# print(class_prob.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-afgyayPdhZD"
      },
      "source": [
        "##### Approch 2: Use enc_state (final hidden state)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "95dQd_ZWdhZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9a7e016-3c52-4100-85c4-c7ac684e632f"
      },
      "source": [
        "class_prob = tf.nn.sigmoid(dense_layer)\n",
        "print(class_prob.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oCk-3f0HdhZQ"
      },
      "source": [
        "#### Loss and Optimizers [softmax_cross_entropy]\n",
        "Note that `onehot_labels` and `logits` must have the same shape, e.g. `[batch_size, num_classes]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dPC78sfudhZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b9667eee-ab69-4fc4-cee9-2e242bd5f49b"
      },
      "source": [
        "print(y_placeholder.shape)\n",
        "print(class_prob.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?,)\n",
            "(50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NmTG_d97dhZb",
        "colab": {}
      },
      "source": [
        "# Loss function - softmax cross entropy\n",
        "y_ = tf.cast(y_placeholder[:, None], dtype=tf.float32)\n",
        "cost = -y_*tf.log(class_prob + 1e-12) - (1-y_)*tf.log(1-class_prob + 1e-12)\n",
        "cost = tf.reduce_mean(cost)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.train.AdamOptimizer(0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5HZsy92ldhZk",
        "colab": {}
      },
      "source": [
        "train_op = optimizer.minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gItZCqGldhZs",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1TU0Q9cZdhZ1"
      },
      "source": [
        "#### Tensorflow Sessions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uULIVWwIdhZ3",
        "colab": {}
      },
      "source": [
        "sess_config = tf.ConfigProto()\n",
        "sess_config.gpu_options.allow_growth = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NEwrPeXdhZ_",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession(config=sess_config)\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e9o41MaAdhaL"
      },
      "source": [
        "#### Minibatch Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fS15WoQpdhaS",
        "colab": {}
      },
      "source": [
        "random.seed(41)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uyx3w39Vdham",
        "colab": {}
      },
      "source": [
        "random.shuffle(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "meRB_fgndha0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ddb7be3-031d-4bb6-8fdb-1e88a0ddd7ac"
      },
      "source": [
        "train_n = len(train_data)\n",
        "train_n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQPMfp-HdhbB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18c60397-b17f-4e22-be32-568abf1a11d5"
      },
      "source": [
        "test_n = len(test_data)\n",
        "test_n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mdrJDKc3dhbk",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "9931a942-4ab2-42ea-cb15-62607a96e6ac"
      },
      "source": [
        "for _e in range(2):\n",
        "    # Mix things up a bit.\n",
        "    random.shuffle(train_data)\n",
        "    pbar = tqdm_notebook(range(0, train_n, BATCH_SIZE))\n",
        "    batch_loss = 0\n",
        "    bxi = 0\n",
        "    for m in pbar:\n",
        "        n = m + BATCH_SIZE\n",
        "        if n <= train_n:\n",
        "            # print(\"Epoch Complete... \\n\")\n",
        "\n",
        "            input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
        "            input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
        "            true_class_batch = np.zeros((BATCH_SIZE))\n",
        "            for i in range(m, n):\n",
        "                b,a = en_lang.encodeSentence2(train_data[i][0], MAX_SEQ_LEN)\n",
        "                input_batch[i-m,:] = a\n",
        "                input_lens_batch[i-m] = b\n",
        "                true_class_batch[i-m] = train_data[i][1]\n",
        "\n",
        "            feed_dict={\n",
        "                input_ids: input_batch,\n",
        "                input_lens: input_lens_batch,\n",
        "                y_placeholder: true_class_batch,\n",
        "                keep_prob: 0.6\n",
        "            }\n",
        "            sess.run(train_op, feed_dict=feed_dict)\n",
        "            batch_loss += sess.run(cost, feed_dict=feed_dict)\n",
        "            pbar.set_description(f\"Epoch: {_e} >> Loss: {batch_loss/(bxi+1):2.2F}:\")\n",
        "            bxi += 1\n",
        "            if (1 + n//BATCH_SIZE) % 100 == 0:\n",
        "                small_test()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef0f09218b1946a9b8517860380b28ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 75.02, Recall: 80.98, F1-Score: 77.89\n",
            "Precision: 80.71, Recall: 76.70, F1-Score: 78.66\n",
            "Precision: 84.36, Recall: 68.81, F1-Score: 75.80\n",
            "Precision: 79.34, Recall: 82.32, F1-Score: 80.80\n",
            "Precision: 77.04, Recall: 87.30, F1-Score: 81.85\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90847ba60cca42798daa0d0b4025ac3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Precision: 79.46, Recall: 84.27, F1-Score: 81.80\n",
            "Precision: 84.78, Recall: 73.07, F1-Score: 78.49\n",
            "Precision: 82.32, Recall: 79.57, F1-Score: 80.92\n",
            "Precision: 80.07, Recall: 83.76, F1-Score: 81.87\n",
            "Precision: 76.02, Recall: 88.31, F1-Score: 81.70\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P8r-jJggoKUj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f6ba741-d0b8-48f5-dd30-8b3d25dbfaef"
      },
      "source": [
        "print(BATCH_SIZE,test_n)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P1cBBzy-kO9G",
        "colab": {}
      },
      "source": [
        "\n",
        "def small_test_modified():\n",
        "    all_true = []\n",
        "    all_preds = []\n",
        "    name = []\n",
        "    for m in range(0, test_n, BATCH_SIZE):\n",
        "        n = m + BATCH_SIZE\n",
        "        if n > test_n:\n",
        "            break\n",
        "\n",
        "        input_batch = np.zeros((BATCH_SIZE, MAX_SEQ_LEN), dtype=np.int32)\n",
        "        input_lens_batch = np.zeros((BATCH_SIZE,), dtype=np.int32)\n",
        "        true_class_batch = np.zeros((BATCH_SIZE))\n",
        "        for i in range(m, n):\n",
        "            b,a = en_lang.encodeSentence2(test_data[i][0], MAX_SEQ_LEN)\n",
        "            input_batch[i-m,:] = a\n",
        "            input_lens_batch[i-m] = b\n",
        "            true_class_batch[i-m] = test_data[i][1]\n",
        "            name.append(test_data[i][2])\n",
        "\n",
        "        feed_dict={\n",
        "            input_ids: input_batch,\n",
        "            input_lens: input_lens_batch,\n",
        "            keep_prob: 1.0\n",
        "        }\n",
        "        pred_batch = sess.run(class_prob, feed_dict=feed_dict)\n",
        "        # acc = accuracy_score(true_class_batch, pred_batch > 0.5)\n",
        "        all_true.extend(list(true_class_batch))\n",
        "        all_preds.extend(list(pred_batch[:,0]))\n",
        "    \n",
        "    all_true = np.array(all_true)\n",
        "    all_preds = np.array(all_preds)\n",
        "    prec = precision_score(all_true, all_preds > 0.5)*100\n",
        "    rec = recall_score(all_true, all_preds > 0.5)*100\n",
        "    f1 = f1_score(all_true, all_preds > 0.5)*100\n",
        "    print(f\"Precision: {prec:2.2F}, Recall: {rec:2.2F}, F1-Score: {f1:2.2F}\")\n",
        "    return all_preds,all_true,name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rU6S_UsMkZ1P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4964acb6-3692-4102-b151-7d5210dda844"
      },
      "source": [
        "pred,tru,name = small_test_modified()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 75.70, Recall: 88.77, F1-Score: 81.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nLmeuC3jkfdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d34de75-a0d0-432c-ef9b-5bfcb8829ea7"
      },
      "source": [
        "lis =[]\n",
        "for i in  range(0,len(name)):\n",
        "    lis.append(str(name[i]+','+ str(pred[i])))\n",
        "len(lis)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67EyFXvmkgvp",
        "colab": {}
      },
      "source": [
        "file = open(\"output.csv\",\"w\")\n",
        "file.write('filename,prob_positive')\n",
        "for i in range(0,len(name)):\n",
        "    file.write('\\n')\n",
        "    file.write(lis[i])\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uWmZ-CZgt0fF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4be56c41-17c3-4896-90b7-3d55b2280de2"
      },
      "source": [
        "def file_len(fname):\n",
        "    with open(fname) as f:\n",
        "        for i, l in enumerate(f):\n",
        "            pass\n",
        "    return i + 1\n",
        "\n",
        "file_len('output.csv')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eRmNhvS5dhb0"
      },
      "source": [
        "References: https://github.com/bsantraigi/Tensorflow-RNN-Tutorials/blob/master/Sentiment%20Analysis%20v2.ipynb\n",
        "\n",
        "### Improvemetns over Vanila RNN\n",
        "\n",
        "Ahieved improvement in f1-score:\n",
        "from ~77% to 81.72%\n",
        "\n",
        "Made modifications to:\n",
        " - lstm size \n",
        " - dropout\n",
        " - Added more hidden layers to the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tBJgxSQ6dhb3",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}